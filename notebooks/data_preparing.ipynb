{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37d36ae8-60e4-48d8-a221-7528e4800af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75075a3e-7dae-4ddf-a6fa-7851767f85c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data_train = datasets.load_dataset(\"stanfordnlp/imdb\")['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23cdefed-d004-4003-b6dc-f20f8db5a802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([12500, 12500]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(sentiments, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5013ef6-8988-48ec-85c7-a1a8008cf684",
   "metadata": {},
   "source": [
    "# Как составлять пары:\n",
    "* В данных равное количество позитивных и негативных отзывов (по 12500).\n",
    "* Максимально возможное количество пар (Positive | Negative) которые можно составить $12500^2$.\n",
    "* Но так как при обучении reward модели важно, чтобы данные не повторялись. Я решил просто сконкатенировать их в зависимости от индекса (всего получается 12500 пар)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6125705a-05ca-4aee-acc3-7755a053da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = len(imdb_data_train)\n",
    "half = total_samples // 2\n",
    "# first half of the data - negative comments, the rest - positive\n",
    "neg_comm = imdb_data_train.select(range(half)) \n",
    "pos_comm = imdb_data_train.select(range(half, total_samples))\n",
    "\n",
    "# data consistency check\n",
    "assert sum(neg_comm['label']) == 0\n",
    "assert sum(pos_comm['label']) == len(pos_comm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d9d13e7-65e4-483c-818f-588880158762",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_dataset = datasets.Dataset.from_dict(\n",
    "    {\n",
    "        \"negative_comment\" : neg_comm['text'],\n",
    "        \"positive_comment\" : pos_comm['text'],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e7b1daf8-45cf-4a5d-801e-064524bb7862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141a0699c2e1495aaf4eb7e1b37b721c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/12500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pairs_dataset.save_to_disk('comment_pairs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alignment",
   "language": "python",
   "name": "alignment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
